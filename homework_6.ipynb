{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Practical Classification: Support Vector Machines\"\n",
    "collection: publications\n",
    "permalink: /notebooks/classification_2\n",
    "excerpt: 'This notebook explores the implementation of basic classification algorithms. EE PMP 559, Spring 2019'\n",
    "date: 2019-05-02\n",
    "paperurl: 'https://github.com/cpatdowling/ee559'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical Classification: Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like logistic regression, Support Vector Machines (SVM) are are another commonly used algorithm for classification. The primary difference between these algorithms is their loss functions, in the binary case:\n",
    "\n",
    "SVM loss: $\\mathcal{L}(y, \\hat{y}) = \\sum_{i} y_i - \\max(0, 1 - y_{i}\\omega^{T}x_{i})$\n",
    "\n",
    "Logistic Regression loss: $\\mathcal{L}(y, \\hat{y}) = \\sum_{i} y_i - \\log(1 + e^{1 - y_{i}\\omega^{T}x_{i}})$\n",
    "\n",
    "The weights $\\omega$ that minimize the loss function gives us the model that labels data either 0 or 1. The output label for a sample $x_{i}$ is determined by which side of the linear decision boundary they fall on, that is $\\omega^{T}x_{i}$ being greater than or less than 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression isn't as robust to outliers, but its loss function is differentiable and important in many applications like neural networks. SVM is robust to outliers and easy to apply non-linear kernels to (when the data isn't separable by a straight line), but like linear regression with L1 regularization (LASSO), requires a slower algorithm to determine a loss-minimizing solution. We can draw on our intuition from regression the effect of the choice of norm has on the loss function to see how SVM is robust to outliers while logistic regression is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<center>Fig. 1</center>\n",
    "<center>![svm vs log loss](figs/svm_vs_log_loss.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As in the previous homework, we'll use sklearn. Read the manpage for [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) before starting the assignment. Most machine learning toolkits treat algorithms for the same type of task (in this case, classification) the same. You'll find that training and testing an SVM is _identical_ to training and testing the logistic regression classifier we generated in the previous homework. You are encouraged to reuse and, if helpful, simplify your code or the code found in the homework 5 solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data for assignment\n",
    "training_data = np.loadtxt(\"homework_6_train.txt\")\n",
    "X_train = training_data[:,0:2] #selects columns 1 and 2, which are the x and y coords of the data\n",
    "Y_train = training_data[:,2] #selections column 3, which is the 0 or 1 label of the data\n",
    "\n",
    "test_data = np.loadtxt(\"homework_6_test.txt\")\n",
    "X_test = test_data[:,0:2]\n",
    "Y_test = test_data[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plotting each class seperately, not important for training the models\n",
    "X_1 = []\n",
    "X_2 = []\n",
    "for row in range(X_train.shape[0]):\n",
    "    if Y_train[row] == 0:\n",
    "        X_1.append(X_train[row,:])\n",
    "    else:\n",
    "        X_2.append(X_train[row,:])\n",
    "X_1 = np.asarray(X_1)\n",
    "X_2 = np.asarray(X_2)\n",
    "\n",
    "plt.scatter(X_1[:,0], X_1[:,1], label=\"Class 1\")\n",
    "plt.scatter(X_2[:,0], X_2[:,1], label=\"Class 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "Using a SVM on the training data set X_train and Y_train, train a classifier. Use the model object function settings I've provided below. Compute and print the training precision and recall. Additionally, compute the _test_ precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert your code here\n",
    "\n",
    "svm_model_obj = SVC(gamma='auto', kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Problem 2\n",
    "\n",
    "Train a logistic regression classifier on the training data set X_train and Y_train. Compute just the _test_ precision and recall for the logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3a\n",
    "\n",
    "Using the solution to the bonus problem in Homework 5, plot the data and the decision boundaries for both the SVM and logistic regression classifiers for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3b\n",
    "\n",
    "Plot the data and the decision boundaries for both the SVM and logistic regression classifiers for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bonus 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I've generated a data set that can only be seperated by a circluar boundary. This is the worst case scenario for a model that attempts to sepearte data with a straight line. But recall from our regression assignments: if we know the _type_ of function we want to fit, we can pass the data through a kernel (in this problem we use the [radial basis function](https://en.wikipedia.org/wiki/Radial_basis_function_kernel) (RBF)---a very powerful basis). Using the SVM model code you've written above and the data provided here, use the following model function settings to seperate the data and draw the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_bonus = np.loadtxt(\"homework_6_bonus.txt\")\n",
    "X_b = data_bonus[:,0:2]\n",
    "Y_b = data_bonus[:,2]\n",
    "\n",
    "X_1 = []\n",
    "X_2 = []\n",
    "for row in range(X_b.shape[0]):\n",
    "    if Y_b[row] == 0:\n",
    "        X_1.append(X_b[row,:])\n",
    "    else:\n",
    "        X_2.append(X_b[row,:])\n",
    "X_1 = np.asarray(X_1)\n",
    "X_2 = np.asarray(X_2)\n",
    "\n",
    "plt.gca().set_aspect('equal') \n",
    "plt.scatter(X_1[:,0], X_1[:,1], label=\"Class 1\")\n",
    "plt.scatter(X_2[:,0], X_2[:,1], label=\"Class 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert your code here\n",
    "\n",
    "svm_model_obj = SVC(gamma='auto', kernel='rbf')  #very important that the kernel setting is 'rbf', other options are \"poly\" or \"linear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
